{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using CounterfactualExplanations.update! in module Main conflicts with an existing identifier.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "evaluate_model (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Distributions\n",
    "using Random\n",
    "using Flux, Statistics, ProgressMeter, Plots, TaijaData, Distances\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: onehotbatch, onecold, crossentropy, logitcrossentropy, mse, throttle, update!, push!\n",
    "using Base.Iterators: repeated, partition\n",
    "using LinearAlgebra: norm\n",
    "using CounterfactualExplanations\n",
    "using Distances\n",
    "using BSON\n",
    "\n",
    "include(\"../utils/train.jl\")\n",
    "include(\"../utils/plot.jl\")\n",
    "include(\"../utils/evaluate.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial attack algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PGD (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function FGSM(model, loss, x, y; ϵ = 0.3, clamp_range = (0, 1))\n",
    "    grads = gradient(x -> loss(model(x), y), x)[1]\n",
    "    x_adv = clamp.(x + (Float32(ϵ) * sign.(grads)), clamp_range...)\n",
    "    return x_adv\n",
    "end\n",
    "\n",
    "function PGD(model, loss, x, y; ϵ = 0.3, step_size = 0.01, iterations = 40, clamp_range = (0, 1))\n",
    "    x_adv = clamp.(x + (randn(Float32, size(x)...) * Float32(step_size)), clamp_range...); # start from the random point\n",
    "    δ = Distances.chebyshev(x, x_adv)\n",
    "    iteration = 1; while (δ < ϵ) && iteration <= iterations\n",
    "        x_adv = FGSM(model, loss, x_adv, y; ϵ = step_size, clamp_range = clamp_range)\n",
    "        δ = chebyshev(x, x_adv)\n",
    "        iteration += 1\n",
    "    end\n",
    "    return x_adv\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(Standardizer(features = Symbol[], …), …).\n",
      "└ @ MLJBase C:\\Users\\Hp\\.julia\\packages\\MLJBase\\hoZmq\\src\\machines.jl:499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6267953329549938 1.2492793703552236 … 3.517855099280236 1.608911071881494; 0.2671551191297572 -1.4013319680081837 … -0.7657178395746824 -0.05065194508699348; … ; -0.6797471205432204 -0.8201877867819832 … -0.6984725427083885 -0.9793538751859174; 0.5088884466495056 0.7983669914605189 … 0.48892440907632917 0.903178188719676], [1, 1, 1, 1, 1, 1, 0, 1, 1, 0  …  0, 1, 0, 1, 1, 0, 0, 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Random.seed!(43)\n",
    "\n",
    "X, y = TaijaData.load_california_housing()\n",
    "# X, y = TaijaData.load_gmsc()\n",
    "# X, y = TaijaData.load_uci_adult()\n",
    "# X, y = TaijaData.load_credit_default()\n",
    "# X, y = TaijaData.load_multi_class(; centers=4)\n",
    "# X, y = TaijaData.load_overlapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Vector{Int64}:\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " ⋮\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = size(X, 2)\n",
    "shuffled_indices = shuffle(1:n)\n",
    "train_ratio = 0.8\n",
    "\n",
    "n_train = Int(floor(train_ratio * n))\n",
    "train_indices = shuffled_indices[1:n_train]\n",
    "test_indices = shuffled_indices[n_train + 1:end]\n",
    "\n",
    "x_train = X[:, train_indices]\n",
    "y_train = y[train_indices]\n",
    "\n",
    "x_test = X[:, test_indices]\n",
    "y_test = y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.360941954494169, 119.38737362611174)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extrema(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00378496447909859"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1534893086401663"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{Float64}:\n",
       " -0.35395138338882964\n",
       "  1.1411245457258214\n",
       " -0.661790490598118\n",
       " -0.05370511582762124\n",
       " -0.6475900725734871\n",
       " -0.11984216643777258\n",
       " -1.3538623184892868\n",
       "  1.2026387523172812"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X[:, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(8 => 10, relu),                 \u001b[90m# 90 parameters\u001b[39m\n",
       "  Dense(10 => 2),                       \u001b[90m# 22 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m112 parameters, 704 bytes."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Chain(\n",
    "    Dense(8, 10, relu; init=Flux.glorot_normal),\n",
    "    Dense(10, 2; init=Flux.glorot_normal)\n",
    ")\n",
    "\n",
    "adv_pgd_strong = deepcopy(model)\n",
    "adv_pgd_medium = deepcopy(model)\n",
    "adv_pgd_weak = deepcopy(model)\n",
    "\n",
    "spare = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(0.001, (0.9, 0.999), 1.0e-8, IdDict{Any, Any}())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss(x, y) = logitcrossentropy(x, y) # Not defining softmax in the model to help with CE\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "clamp_range = extrema(X)\n",
    "opt = ADAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count(a -> a == 1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean model (no adversarial training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Average loss: 0.6015058772563935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Layer with Float32 parameters got Float64 input.\n",
      "│   The input will be converted, but any earlier layers may be very slow.\n",
      "│   layer = Dense(8 => 10, relu)\n",
      "│   summary(x) = 8×32 Matrix{Float64}\n",
      "└ @ Flux C:\\Users\\Hp\\.julia\\packages\\Flux\\Wz6D4\\src\\layers\\stateless.jl:60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Average loss: 0.5146374053955078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  10%|█████                                    |  ETA: 0:02:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "Average loss: 0.47426541805267336\n",
      "Epoch: 4\n",
      "Average loss: 0.45124980902671813\n",
      "Epoch: 5\n",
      "Average loss: 0.4358201282024384\n",
      "Epoch: 6\n",
      "Average loss: 0.4227229048013687\n",
      "Epoch: 7\n",
      "Average loss: 0.41268244457244874\n",
      "Epoch: 8\n",
      "Average loss: 0.40472635710239413\n",
      "Epoch: 9\n",
      "Average loss: 0.39845274126529695\n",
      "Epoch: 10\n",
      "Average loss: 0.3921532881259918\n",
      "Epoch: 11\n",
      "Average loss: 0.38660020542144774\n",
      "Epoch: 12\n",
      "Average loss: 0.3825889868736267\n",
      "Epoch: 13\n",
      "Average loss: 0.3790155427455902\n",
      "Epoch: 14\n",
      "Average loss: 0.3747734922170639\n",
      "Epoch: 15\n",
      "Average loss: 0.3711442241668701\n",
      "Epoch: 16\n",
      "Average loss: 0.36917440271377566\n",
      "Epoch: 17\n",
      "Average loss: 0.36700569051504134\n",
      "Epoch: 18\n",
      "Average loss: 0.3645698983669281\n",
      "Epoch: 19\n",
      "Average loss: 0.36261710727214813\n",
      "Epoch: 20\n",
      "Average loss: 0.36039947867393496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\u001b[K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20-element Vector{Any}:\n",
       " 0.6015058772563935\n",
       " 0.5146374053955078\n",
       " 0.47426541805267336\n",
       " 0.45124980902671813\n",
       " 0.4358201282024384\n",
       " 0.4227229048013687\n",
       " 0.41268244457244874\n",
       " 0.40472635710239413\n",
       " 0.39845274126529695\n",
       " 0.3921532881259918\n",
       " 0.38660020542144774\n",
       " 0.3825889868736267\n",
       " 0.3790155427455902\n",
       " 0.3747734922170639\n",
       " 0.3711442241668701\n",
       " 0.36917440271377566\n",
       " 0.36700569051504134\n",
       " 0.3645698983669281\n",
       " 0.36261710727214813\n",
       " 0.36039947867393496"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vanilla_losses = vanilla_train(model, loss, opt, x_train, y_train, epochs, batch_size, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adversarial training: PGD with epsilon 0.1 and 13 iterations of 0.01 step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Average loss: 1.1794280576705933\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  10%|█████                                    |  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.1791986560821532\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  15%|███████                                  |  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.1780894556045531\n",
      "Epoch: 4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  20%|█████████                                |  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 1.177021487236023\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  25%|███████████                              |  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.176909496307373\n",
      "Epoch: 6"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  30%|█████████████                            |  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 1.176136549949646\n",
      "Epoch: 7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  35%|███████████████                          |  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 1.1741202688217163\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  40%|█████████████████                        |  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.174392972946167\n",
      "Epoch: 9"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  45%|███████████████████                      |  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 1.1731367793083192\n",
      "Epoch: 10\n",
      "Average loss: 1.1734899697303771\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  55%|███████████████████████                  |  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.172388087272644\n",
      "Epoch: 12"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  60%|█████████████████████████                |  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 1.1722591047286988\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  65%|███████████████████████████              |  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.172169141292572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  70%|█████████████████████████████            |  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14\n",
      "Average loss: 1.1710399956703186\n",
      "Epoch: 15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  75%|███████████████████████████████          |  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 1.1709223408699037\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  80%|█████████████████████████████████        |  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.1710241751670838\n",
      "Epoch: 17\n",
      "Average loss: 1.1702409310340882\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  90%|█████████████████████████████████████    |  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.1705050539970399\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  95%|███████████████████████████████████████  |  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.1703418545722961\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\u001b[K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.1702612476348877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20-element Vector{Any}:\n",
       " 1.1794280576705933\n",
       " 1.1791986560821532\n",
       " 1.1780894556045531\n",
       " 1.177021487236023\n",
       " 1.176909496307373\n",
       " 1.176136549949646\n",
       " 1.1741202688217163\n",
       " 1.174392972946167\n",
       " 1.1731367793083192\n",
       " 1.1734899697303771\n",
       " 1.172388087272644\n",
       " 1.1722591047286988\n",
       " 1.172169141292572\n",
       " 1.1710399956703186\n",
       " 1.1709223408699037\n",
       " 1.1710241751670838\n",
       " 1.1702409310340882\n",
       " 1.1705050539970399\n",
       " 1.1703418545722961\n",
       " 1.1702612476348877"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adversarial_losses_strong = adversarial_train(adv_pgd_strong, loss, opt, x_train, y_train, epochs, batch_size, PGD, 0, 1, 0.3; attack_method=:PGD, iterations=40, step_size=0.01, clamp_range=clamp_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adversarial training: PGD with epsilon 0.05 and 7 iterations of 0.01 step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Average loss: 1.3308736066818236\n",
      "Epoch: 2\n",
      "Average loss: 1.1531618180274963\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  15%|███████                                  |  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.0817458477020263\n",
      "Epoch: 4\n",
      "Average loss: 1.049683916091919\n",
      "Epoch: 5\n",
      "Average loss: 1.0303350548744201\n",
      "Epoch: 6"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  30%|█████████████                            |  ETA: 0:00:01\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 1.0206252689361572\n",
      "Epoch: 7\n",
      "Average loss: 1.0139870595932008\n",
      "Epoch: 8\n",
      "Average loss: 1.0091471314430236\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  45%|███████████████████                      |  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.004466987133026\n",
      "Epoch: 10\n",
      "Average loss: 0.9995256018638611\n",
      "Epoch: 11\n",
      "Average loss: 0.9947215929031372\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  60%|█████████████████████████                |  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.9906098599433899\n",
      "Epoch: 13\n",
      "Average loss: 0.9862371153831482\n",
      "Epoch: 14\n",
      "Average loss: 0.9848227453231811\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  75%|███████████████████████████████          |  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.9827404928207397\n",
      "Epoch: 16\n",
      "Average loss: 0.9797001795768738\n",
      "Epoch: 17\n",
      "Average loss: 0.9771924352645874\n",
      "Epoch: 18"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  90%|█████████████████████████████████████    |  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.9763699388504028\n",
      "Epoch: 19\n",
      "Average loss: 0.9743294353485108\n",
      "Epoch: 20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\u001b[K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.9726215448379517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20-element Vector{Any}:\n",
       " 1.3308736066818236\n",
       " 1.1531618180274963\n",
       " 1.0817458477020263\n",
       " 1.049683916091919\n",
       " 1.0303350548744201\n",
       " 1.0206252689361572\n",
       " 1.0139870595932008\n",
       " 1.0091471314430236\n",
       " 1.004466987133026\n",
       " 0.9995256018638611\n",
       " 0.9947215929031372\n",
       " 0.9906098599433899\n",
       " 0.9862371153831482\n",
       " 0.9848227453231811\n",
       " 0.9827404928207397\n",
       " 0.9797001795768738\n",
       " 0.9771924352645874\n",
       " 0.9763699388504028\n",
       " 0.9743294353485108\n",
       " 0.9726215448379517"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adversarial_losses_medium = adversarial_train(adv_pgd_medium, loss, opt, x_train, y_train, epochs, batch_size, PGD, 0, 1, 0.1; attack_method=:PGD, iterations=13, step_size=0.01, clamp_range=clamp_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adversarial training: PGD with epsilon 0.01 and 13 iterations of 0.001 step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Average loss: 1.2436175413131714\n",
      "Epoch: 2\n",
      "Average loss: 1.0704891090393067\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  25%|███████████                              |  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.9979364490509033\n",
      "Epoch: 4\n",
      "Average loss: 0.962753788471222\n",
      "Epoch: 5\n",
      "Average loss: 0.9396940665245056\n",
      "Epoch: 6\n",
      "Average loss: 0.9238256707191467\n",
      "Epoch: 7\n",
      "Average loss: 0.9154068455696106\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  60%|█████████████████████████                |  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.9014751884937287\n",
      "Epoch: 9\n",
      "Average loss: 0.8933466787338257\n",
      "Epoch: 10\n",
      "Average loss: 0.8875015015602112\n",
      "Epoch: 11\n",
      "Average loss: 0.8836750316619874\n",
      "Epoch: 12\n",
      "Average loss: 0.8749061369895935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  85%|███████████████████████████████████      |  ETA: 0:00:00\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\n",
      "Average loss: 0.8728516874313355\n",
      "Epoch: 14\n",
      "Average loss: 0.8642656865119934\n",
      "Epoch: 15\n",
      "Average loss: 0.8619214978218078\n",
      "Epoch: 16\n",
      "Average loss: 0.8599686172008515\n",
      "Epoch: 17\n",
      "Average loss: 0.8565892689228057\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\u001b[K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.8543297114372254\n",
      "Epoch: 19\n",
      "Average loss: 0.8476223366260529\n",
      "Epoch: 20\n",
      "Average loss: 0.8463143496513367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20-element Vector{Any}:\n",
       " 1.2436175413131714\n",
       " 1.0704891090393067\n",
       " 0.9979364490509033\n",
       " 0.962753788471222\n",
       " 0.9396940665245056\n",
       " 0.9238256707191467\n",
       " 0.9154068455696106\n",
       " 0.9014751884937287\n",
       " 0.8933466787338257\n",
       " 0.8875015015602112\n",
       " 0.8836750316619874\n",
       " 0.8749061369895935\n",
       " 0.8728516874313355\n",
       " 0.8642656865119934\n",
       " 0.8619214978218078\n",
       " 0.8599686172008515\n",
       " 0.8565892689228057\n",
       " 0.8543297114372254\n",
       " 0.8476223366260529\n",
       " 0.8463143496513367"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adversarial_losses_weak = adversarial_train(adv_pgd_weak, loss, opt, x_train, y_train, epochs, batch_size, PGD, 0, 1, 0.05; attack_method=:PGD, iterations=7, step_size=0.01, clamp_range=clamp_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating robustness: accuracy on clean and adversarial examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 4 entries:\n",
       "  \"adversary_forced_error\" => 640\n",
       "  \"clean_accuracy\"         => 0.857\n",
       "  \"adversary_changed\"      => 640\n",
       "  \"adversarial_accuracy\"   => 0.217"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overview = evaluate_model(x_test, y_test, 0, 1, clean_model, loss, PGD, 0.2; iterations=26, step_size=0.01, attack_method=:PGD, clamp_range=clamp_range)\n",
    "\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times 1 predicted: 496\n",
      "times 0 predicted: 504\n",
      "times 1 was correct: 426\n",
      "times 0 was correct: 440\n"
     ]
    }
   ],
   "source": [
    "pred1 = 0\n",
    "pred0 = 0\n",
    "corr1 = 0\n",
    "corr0 = 0\n",
    "\n",
    "for index = 1:1000\n",
    "    datapt = x_test[:, index]\n",
    "    actual = y_test[index]\n",
    "    prediction = (model(datapt) |> Flux.onecold |> getindex) - 1\n",
    "\n",
    "    if prediction == 1\n",
    "        pred1 += 1\n",
    "    else\n",
    "        pred0 += 1\n",
    "    end\n",
    "\n",
    "    if prediction == 1 && actual == 1\n",
    "        corr1 += 1\n",
    "    elseif prediction == 0 && actual == 0\n",
    "        corr0 += 1\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"times 1 predicted: \", pred1)\n",
    "println(\"times 0 predicted: \", pred0)\n",
    "println(\"times 1 was correct: \", corr1)\n",
    "println(\"times 0 was correct: \", corr0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adversarial models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 4 entries:\n",
       "  \"adversary_forced_error\" => 490\n",
       "  \"clean_accuracy\"         => 0.84\n",
       "  \"adversary_changed\"      => 490\n",
       "  \"adversarial_accuracy\"   => 0.35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_to_use = adv_pgd_strong\n",
    "# model_to_use = adv_pgd_medium\n",
    "model_to_use = adv_pgd_weak\n",
    "\n",
    "overview_adv = evaluate_model(x_test, y_test, 0, 1, model_to_use, loss, PGD, 0.2; step_size=0.01, iterations=26, attack_method= :PGD, clamp_range = clamp_range)\n",
    "\n",
    "overview_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times 1 predicted: 397\n",
      "times 0 predicted: 603\n",
      "times 1 was correct: 322\n",
      "times 0 was correct: 435\n"
     ]
    }
   ],
   "source": [
    "pred1 = 0\n",
    "pred0 = 0\n",
    "corr1 = 0\n",
    "corr0 = 0\n",
    "\n",
    "for index = 1:1000\n",
    "    datapt = x_test[:, index]\n",
    "    actual = y_test[index]\n",
    "    prediction = (model_to_use(datapt) |> Flux.onecold |> getindex) - 1\n",
    "\n",
    "    if prediction == 1\n",
    "        pred1 += 1\n",
    "    elseif prediction == 0\n",
    "        pred0 += 1\n",
    "    end\n",
    "\n",
    "    if prediction == 1 && actual == 1\n",
    "        corr1 += 1\n",
    "    elseif prediction == 0 && actual == 0\n",
    "        corr0 += 1\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"times 1 predicted: \", pred1)\n",
    "println(\"times 0 predicted: \", pred0)\n",
    "println(\"times 1 was correct: \", corr1)\n",
    "println(\"times 0 was correct: \", corr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON: @save, @load\n",
    "\n",
    "@save \"../models/CaliHousing/clean_20ep_32bs.bson\" model\n",
    "@save \"../models/CaliHousing/adv_20ep_32bs_40it_0.01ss_0.3eps.bson\" adv_pgd_strong\n",
    "@save \"../models/CaliHousing/adv_20ep_32bs_13it_0.01ss_0.1eps.bson\" adv_pgd_medium\n",
    "@save \"../models/CaliHousing/adv_20ep_32bs_7it_0.01ss_0.05eps.bson\" adv_pgd_weak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counterfactual generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(8 => 10, relu),                 \u001b[90m# 90 parameters\u001b[39m\n",
       "  Dense(10 => 2),                       \u001b[90m# 22 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m112 parameters, 704 bytes."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_model = BSON.load(\"../models/CaliHousing/clean_20ep_32bs.bson\")[:model]\n",
    "adv_pgd_strong = BSON.load(\"../models/CaliHousing/adv_20ep_32bs_40it_0.01ss_0.3eps.bson\")[:adv_pgd_strong]\n",
    "adv_pgd_medium = BSON.load(\"../models/CaliHousing/adv_20ep_32bs_13it_0.01ss_0.1eps.bson\")[:adv_pgd_medium]\n",
    "adv_pgd_weak = BSON.load(\"../models/CaliHousing/adv_20ep_32bs_7it_0.01ss_0.05eps.bson\")[:adv_pgd_weak]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure of Implausibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_euclidean (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Distances\n",
    "\n",
    "function distance_from_targets(\n",
    "    ce::AbstractCounterfactualExplanation;\n",
    "    agg = mean,\n",
    "    n_nearest_neighbors::Union{Int,Nothing} = 100,\n",
    "    p::Int = 2,\n",
    ")\n",
    "    target_idx = ce.data.output_encoder.labels .== ce.target\n",
    "    target_samples = ce.data.X[:, target_idx]\n",
    "    x′ = CounterfactualExplanations.counterfactual(ce)\n",
    "    loss = map(eachslice(x′, dims = ndims(x′))) do x\n",
    "        Δ = map(eachcol(target_samples)) do xsample\n",
    "            norm(x - xsample, p)\n",
    "            # euclidean(x, xsample)\n",
    "            # chebyshev(x, xsample)\n",
    "        end\n",
    "        if n_nearest_neighbors != nothing\n",
    "            Δ = sort(Δ)[1:n_nearest_neighbors]\n",
    "        end\n",
    "        return mean(Δ)\n",
    "    end\n",
    "    loss = agg(loss)[1]\n",
    "\n",
    "    return loss\n",
    "\n",
    "end\n",
    "\n",
    "function custom_euclidean(counterfactual, label, x_train, y_train, n_datapoints)\n",
    "    indices = findall(x -> x == label, y_train)\n",
    "    random_indices = rand(indices, n_datapoints)\n",
    "\n",
    "    distance = 0\n",
    "\n",
    "    for index in random_indices\n",
    "        distance += norm(counterfactual - x_train[:, index])\n",
    "    end\n",
    "\n",
    "    return distance/n_datapoints\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CounterfactualExplanations.Models.Model(Chain(Dense(8 => 10, relu), Dense(10 => 2)), :classification_multi, Chain(Dense(8 => 10, relu), Dense(10 => 2)), MLP())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flux_clean = CounterfactualExplanations.MLP(clean_model; likelihood=:classification_multi)\n",
    "flux_adv_strong = CounterfactualExplanations.MLP(adv_pgd_strong; likelihood=:classification_multi)\n",
    "flux_adv_medium = CounterfactualExplanations.MLP(adv_pgd_medium; likelihood=:classification_multi) \n",
    "flux_adv_weak = CounterfactualExplanations.MLP(adv_pgd_weak; likelihood=:classification_multi) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Layer with Float32 parameters got Float64 input.\n",
      "│   The input will be converted, but any earlier layers may be very slow.\n",
      "│   layer = Dense(8 => 10, relu)\n",
      "│   summary(x) = 8×1 Matrix{Float64}\n",
      "└ @ Flux C:\\Users\\Hp\\.julia\\packages\\Flux\\Wz6D4\\src\\layers\\stateless.jl:60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CounterfactualExplanation\n",
      "\u001b[0m\u001b[1mConvergence: ❌ after 1000 steps.\u001b[22m\n",
      "distance: 1.4421449133726187\n",
      "label to reach: 1\n",
      "label reached: 1\n",
      "did CE cross boundary? true\n",
      "valid? [[1.0]]\n"
     ]
    }
   ],
   "source": [
    "using CounterfactualExplanations.Evaluation: evaluate, validity\n",
    "\n",
    "# model_to_use = flux_clean\n",
    "model_to_use = flux_adv_strong\n",
    "# model_to_use = flux_adv_medium\n",
    "# model_to_use = flux_adv_weak\n",
    "\n",
    "# random point's Counterfactual\n",
    "index = rand(1:1000)\n",
    "label = y_test[index]\n",
    "println(\"actual label: \", label)\n",
    "\n",
    "different_label = (label == 1 ? 0 : 1)\n",
    "\n",
    "counterfactual_data = CounterfactualData(x_train, y_train)\n",
    "generator = CounterfactualExplanations.ECCoGenerator(; λ=[0.1, 0.1])\n",
    "\n",
    "counterfactual_data.domain = [extrema(X) for var in counterfactual_data.features_continuous]\n",
    "# convergence = CounterfactualExplanations.DecisionThresholdConvergence(decision_threshold=0.5, max_iter=1000)\n",
    "convergence = CounterfactualExplanations.GeneratorConditionsConvergence(decision_threshold=0.5, max_iter=1000)\n",
    " \n",
    "ce = generate_counterfactual(\n",
    "        reshape(x_test[:, index], 8, 1), different_label, counterfactual_data, model_to_use, generator; num_counterfactuals=1, convergence=convergence\n",
    "    )\n",
    "\n",
    "println(ce)\n",
    "\n",
    "ces = CounterfactualExplanations.counterfactual(ce)\n",
    "cf = ces[:, 1]\n",
    "\n",
    "# inf_model = model\n",
    "inf_model = adv_pgd_strong\n",
    "# inf_model = adv_pgd_medium\n",
    "# inf_model = adv_pgd_weak\n",
    "\n",
    "label_reached = (inf_model(cf) |> Flux.onecold |> getindex) - 1\n",
    "\n",
    "println(\"distance: \", distance_from_targets(ce))\n",
    "println(\"label to reach: \", different_label)\n",
    "println(\"label reached: \", label_reached)\n",
    "println(\"did CE cross boundary? \", (label_reached == different_label))\n",
    "println(\"valid? \", evaluate(ce; measure=validity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Vector{Int64}}:\n",
       " [1, 0, 0, 0, 1, 1, 1, 1, 0, 1  …  1, 0, 0, 1, 1, 0, 1, 0, 1, 1]\n",
       " [0, 0, 1, 1, 0, 0, 0, 1, 1, 0  …  0, 1, 1, 0, 1, 0, 1, 0, 0, 0]\n",
       " [1, 1, 0, 0, 0, 0, 1, 0, 0, 1  …  0, 1, 0, 1, 0, 1, 1, 0, 0, 0]\n",
       " [0, 0, 0, 1, 1, 1, 1, 1, 0, 1  …  1, 0, 0, 1, 0, 1, 1, 1, 1, 1]\n",
       " [1, 0, 1, 0, 1, 0, 0, 0, 0, 1  …  1, 1, 1, 0, 1, 0, 0, 1, 1, 0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function generate_split(num_datapoints)\n",
    "    rand(1:num_datapoints, 100)\n",
    "end\n",
    "\n",
    "function target_label(label)\n",
    "    return label == 1 ? 0 : 1\n",
    "end\n",
    "\n",
    "splits = [generate_split(length(y_test)) for _ in 1:5]\n",
    "targets = [[target_label(y_test[num]) for num in split] for split in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " CounterfactualExplanations.Convergence.GeneratorConditionsConvergence(0.5, 0.01, 1000, 0.75)\n",
       " CounterfactualExplanations.Convergence.DecisionThresholdConvergence(0.5, 1000, 0.75)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flux_clean = CounterfactualExplanations.MLP(clean_model; likelihood=:classification_multi)\n",
    "flux_adv_strong = CounterfactualExplanations.MLP(adv_pgd_strong; likelihood=:classification_multi)\n",
    "flux_adv_medium = CounterfactualExplanations.MLP(adv_pgd_medium; likelihood=:classification_multi) \n",
    "flux_adv_weak = CounterfactualExplanations.MLP(adv_pgd_weak; likelihood=:classification_multi) \n",
    "\n",
    "counterfactual_data = CounterfactualData(x_train, y_train)\n",
    "counterfactual_data.domain = [extrema(X) for var in counterfactual_data.features_continuous]\n",
    "generator = CounterfactualExplanations.ECCoGenerator(; λ=[0.1, 0.1])\n",
    "# generator = CounterfactualExplanations.ECCoGenerator(; λ=[0.1, 0.5])\n",
    "convergences = []\n",
    "push!(convergences, CounterfactualExplanations.GeneratorConditionsConvergence(decision_threshold=0.5,max_iter=1000))\n",
    "push!(convergences, CounterfactualExplanations.DecisionThresholdConvergence(decision_threshold=0.5, max_iter=1000))\n",
    "\n",
    "convergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 30 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 40 of split 1 reached\n",
      "datapoint 50 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 60 of split 1 reached\n",
      "datapoint 70 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 100 of split 1 reached\n",
      "here!\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 2 reached\n",
      "datapoint 30 of split 2 reached\n",
      "datapoint 40 of split 2 reached\n",
      "datapoint 50 of split 2 reached\n",
      "datapoint 60 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 70 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 100 of split 2 reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  40%|█████████████████                        |  ETA: 0:07:05\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 3 reached\n",
      "datapoint 30 of split 3 reached\n",
      "datapoint 40 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 50 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 60 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 70 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 3 reached\n",
      "datapoint 100 of split 3 reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  60%|█████████████████████████                |  ETA: 0:04:45\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "datapoint 10 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 30 of split 4 reached\n",
      "datapoint 40 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 50 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 60 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 70 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 4 reached\n",
      "datapoint 100 of split 4 reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  80%|█████████████████████████████████        |  ETA: 0:02:23\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 30 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 40 of split 5 reached\n",
      "datapoint 50 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 60 of split 5 reached\n",
      "datapoint 70 of split 5 reached\n",
      "datapoint 80 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 100 of split 5 reached"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:11:57\u001b[39m\u001b[K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5-element Vector{Any}:\n",
       " 1.4267614255115362\n",
       " 1.5246982977274603\n",
       " 1.476316894570456\n",
       " 1.4781864458496086\n",
       " 1.5886510148647106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_implausibilities_clean_dt = []\n",
    "mean_implausibilities_clean_gc = []\n",
    "total_validity_dt = 0\n",
    "total_validity_gc = 0\n",
    "model_to_use = clean_model\n",
    "skipped_clean = 0\n",
    "\n",
    "@showprogress for (i, split) in enumerate(splits)\n",
    "    println(\"here!\")\n",
    "    implausibilities_dt = []\n",
    "    implausibilities_gc = []\n",
    "    for (j, index) in enumerate(split)\n",
    "\n",
    "        model_pred = (model_to_use(x_test[:, index]) |> Flux.onecold |> getindex) - 1\n",
    "        if model_pred != y_test[index]\n",
    "            skipped_clean += 1\n",
    "            println(\"Skipping because of model misclassification\")\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        if (j % 10 == 0)\n",
    "            println(\"datapoint $j of split $i reached\")\n",
    "        end\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for convergence in convergences\n",
    "            ce = generate_counterfactual(\n",
    "            reshape(x_test'[index, :], 8, 1), targets[i][j], counterfactual_data, flux_clean, generator; num_counterfactuals=1, convergence=convergence\n",
    "            )\n",
    "\n",
    "            implausibility = distance_from_targets(ce)\n",
    "\n",
    "            if count == 0\n",
    "                total_validity_gc += evaluate(ce; measure=validity)[1][1]\n",
    "                push!(implausibilities_gc, implausibility)\n",
    "            elseif count == 1\n",
    "                total_validity_dt += evaluate(ce; measure=validity)[1][1]\n",
    "                push!(implausibilities_dt, implausibility)\n",
    "            end\n",
    "            \n",
    "            count += 1\n",
    "        end\n",
    "    end\n",
    "    push!(mean_implausibilities_clean_dt, mean(implausibilities_dt))\n",
    "    push!(mean_implausibilities_clean_gc, mean(implausibilities_gc))\n",
    "end\n",
    "\n",
    "mean_implausibilities_clean_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skips: 63\n",
      "mean implausibilities using DTC: Any[1.4267614255115362, 1.5246982977274603, 1.476316894570456, 1.4781864458496086, 1.5886510148647106]\n",
      "mean implausibilities using GCC: Any[1.8970965886924729, 2.029216841747039, 2.051623454582683, 1.9991429317202878, 2.083095632022346]\n",
      "Using Decision Threshold Convergence:\n",
      "valid switches: 436.0\n",
      "mean: 1.4989228157047543\n",
      "std: 0.06095862559496609\n",
      "Using Generator Conditions Convergence:\n",
      "valid switches: 436.0\n",
      "mean: 2.012035089752966\n",
      "std: 0.07121993868269524\n"
     ]
    }
   ],
   "source": [
    "println(\"skips: \", skipped_clean)\n",
    "\n",
    "println(\"mean implausibilities using DTC: \", mean_implausibilities_clean_dt)\n",
    "println(\"mean implausibilities using GCC: \", mean_implausibilities_clean_gc)\n",
    "\n",
    "println(\"Using Decision Threshold Convergence:\")\n",
    "\n",
    "println(\"valid switches: \", total_validity_dt)\n",
    "println(\"mean: \", mean(mean_implausibilities_clean_dt))\n",
    "println(\"std: \", std(mean_implausibilities_clean_dt))\n",
    "\n",
    "println(\"Using Generator Conditions Convergence:\")\n",
    "\n",
    "println(\"valid switches: \", total_validity_gc)\n",
    "println(\"mean: \", mean(mean_implausibilities_clean_gc))\n",
    "println(\"std: \", std(mean_implausibilities_clean_gc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 30 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 40 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 50 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 60 of split 1 reached\n",
      "datapoint 70 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 1 reached\n",
      "datapoint 100 of split 1 reached\n",
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 30 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 40 of split 2 reached\n",
      "datapoint 50 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 60 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 100 of split 2 reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  40%|█████████████████                        |  ETA: 0:06:15\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 30 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 40 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 50 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 60 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 70 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 100 of split 3 reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  60%|█████████████████████████                |  ETA: 0:04:12\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 30 of split 4 reached\n",
      "datapoint 40 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 50 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 60 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 70 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 100 of split 4 reached"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  80%|█████████████████████████████████        |  ETA: 0:02:06\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 30 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 40 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 50 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 70 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 100 of split 5 reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:10:38\u001b[39m\u001b[K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5-element Vector{Any}:\n",
       " 1.1249032601576487\n",
       " 1.1697012552973238\n",
       " 1.1731097891522333\n",
       " 1.0750806253737086\n",
       " 1.273030417344753"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_implausibilities_strong_dt = []\n",
    "mean_implausibilities_strong_gc = []\n",
    "total_validity_strong_dt = 0\n",
    "total_validity_strong_gc = 0\n",
    "model_to_use = adv_pgd_strong\n",
    "skipped_strong = 0\n",
    "\n",
    "@showprogress for (i, split) in enumerate(splits)\n",
    "    println(\"here!\")\n",
    "    implausibilities_dt = []\n",
    "    implausibilities_gc = []\n",
    "    for (j, index) in enumerate(split)\n",
    "\n",
    "        model_pred = (model_to_use(x_test[:, index]) |> Flux.onecold |> getindex) - 1\n",
    "        if model_pred != y_test[index]\n",
    "            skipped_strong += 1\n",
    "            println(\"Skipping because of model misclassification\")\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        if (j % 10 == 0)\n",
    "            println(\"datapoint $j of split $i reached\")\n",
    "        end\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for convergence in convergences\n",
    "            ce = generate_counterfactual(\n",
    "            reshape(x_test'[index, :], 8, 1), targets[i][j], counterfactual_data, flux_adv_strong, generator; num_counterfactuals=1, convergence=convergence\n",
    "            )\n",
    "\n",
    "            implausibility = distance_from_targets(ce)\n",
    "\n",
    "            if count == 0\n",
    "                total_validity_strong_gc += evaluate(ce; measure=validity)[1][1]\n",
    "                push!(implausibilities_gc, implausibility)\n",
    "            elseif count == 1\n",
    "                total_validity_strong_dt += evaluate(ce; measure=validity)[1][1]\n",
    "                push!(implausibilities_dt, implausibility)\n",
    "            end\n",
    "            \n",
    "            count += 1\n",
    "        end\n",
    "    end\n",
    "    push!(mean_implausibilities_strong_dt, mean(implausibilities_dt))\n",
    "    push!(mean_implausibilities_strong_gc, mean(implausibilities_gc))\n",
    "end\n",
    "\n",
    "mean_implausibilities_strong_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skips: 108\n",
      "mean implausibilities using DTC: Any[1.1249032601576487, 1.1697012552973238, 1.1731097891522333, 1.0750806253737086, 1.273030417344753]\n",
      "mean implausibilities using GCC: Any[1.5187181720725076, 1.545800406612234, 1.568100018658987, 1.4743692675998696, 1.6121980293570308]\n",
      "Using Decision Threshold Convergence:\n",
      "valid switches: 392.0\n",
      "mean: 1.1631650694651334\n",
      "std: 0.07320322599103032\n",
      "Using Generator Conditions Convergence:\n",
      "valid switches: 392.0\n",
      "mean: 1.543837178860126\n",
      "std: 0.051774754310936345\n"
     ]
    }
   ],
   "source": [
    "println(\"skips: \", skipped_strong)\n",
    "\n",
    "println(\"mean implausibilities using DTC: \", mean_implausibilities_strong_dt)\n",
    "println(\"mean implausibilities using GCC: \", mean_implausibilities_strong_gc)\n",
    "\n",
    "println(\"Using Decision Threshold Convergence:\")\n",
    "\n",
    "println(\"valid switches: \", total_validity_strong_dt)\n",
    "println(\"mean: \", mean(mean_implausibilities_strong_dt))\n",
    "println(\"std: \", std(mean_implausibilities_strong_dt))\n",
    "\n",
    "println(\"Using Generator Conditions Convergence:\")\n",
    "\n",
    "println(\"valid switches: \", total_validity_strong_gc)\n",
    "println(\"mean: \", mean(mean_implausibilities_strong_gc))\n",
    "println(\"std: \", std(mean_implausibilities_strong_gc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 1 reached\n",
      "datapoint 30 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 40 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 50 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 60 of split 1 reached\n",
      "datapoint 70 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 1 reached\n",
      "datapoint 100 of split 1 reached\n",
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 2 reached\n",
      "datapoint 30 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 40 of split 2 reached\n",
      "datapoint 50 of split 2 reached\n",
      "datapoint 60 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 70 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 100 of split 2 reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  40%|█████████████████                        |  ETA: 0:07:07\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 3 reached\n",
      "datapoint 30 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 40 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 50 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 60 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 70 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 100 of split 3 reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  60%|█████████████████████████                |  ETA: 0:04:39\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 30 of split 4 reached\n",
      "datapoint 40 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 50 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 60 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 70 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 100 of split 4 reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  80%|█████████████████████████████████        |  ETA: 0:02:17\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 30 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 70 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 100 of split 5 reached"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:11:17\u001b[39m\u001b[K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5-element Vector{Any}:\n",
       " 1.1495166238552401\n",
       " 1.2144272361734945\n",
       " 1.2003238366939815\n",
       " 1.1653396055424623\n",
       " 1.3173814516920654"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_implausibilities_medium_dt = []\n",
    "mean_implausibilities_medium_gc = []\n",
    "total_validity_medium_dt = 0\n",
    "total_validity_medium_gc = 0\n",
    "model_to_use = adv_pgd_medium\n",
    "skipped_medium = 0\n",
    "\n",
    "@showprogress for (i, split) in enumerate(splits)\n",
    "    println(\"here!\")\n",
    "    implausibilities_dt = []\n",
    "    implausibilities_gc = []\n",
    "    for (j, index) in enumerate(split)\n",
    "\n",
    "        model_pred = (model_to_use(x_test[:, index]) |> Flux.onecold |> getindex) - 1\n",
    "        if model_pred != y_test[index]\n",
    "            skipped_medium += 1\n",
    "            println(\"Skipping because of model misclassification\")\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        if (j % 10 == 0)\n",
    "            println(\"datapoint $j of split $i reached\")\n",
    "        end\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for convergence in convergences\n",
    "            ce = generate_counterfactual(\n",
    "            reshape(x_test'[index, :], 8, 1), targets[i][j], counterfactual_data, flux_adv_medium, generator; num_counterfactuals=1, convergence=convergence\n",
    "            )\n",
    "\n",
    "            implausibility = distance_from_targets(ce)\n",
    "\n",
    "            if count == 0\n",
    "                total_validity_medium_gc += evaluate(ce; measure=validity)[1][1]\n",
    "                push!(implausibilities_gc, implausibility)\n",
    "            elseif count == 1\n",
    "                total_validity_medium_dt += evaluate(ce; measure=validity)[1][1]\n",
    "                push!(implausibilities_dt, implausibility)\n",
    "            end\n",
    "            \n",
    "            count += 1\n",
    "        end\n",
    "    end\n",
    "    push!(mean_implausibilities_medium_dt, mean(implausibilities_dt))\n",
    "    push!(mean_implausibilities_medium_gc, mean(implausibilities_gc))\n",
    "end\n",
    "\n",
    "mean_implausibilities_medium_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skips: 88\n",
      "mean implausibilities using DTC: Any[1.1495166238552401, 1.2144272361734945, 1.2003238366939815, 1.1653396055424623, 1.3173814516920654]\n",
      "mean implausibilities using GCC: Any[1.6993332830514305, 1.8939813805394716, 1.9412652155218406, 1.8185770893336735, 2.0299497927689982]\n",
      "Using Decision Threshold Convergence:\n",
      "valid switches: 412.0\n",
      "mean: 1.2093977507914486\n",
      "std: 0.06575519148018161\n",
      "Using Generator Conditions Convergence:\n",
      "valid switches: 412.0\n",
      "mean: 1.8766213522430828\n",
      "std: 0.1252896706143049\n"
     ]
    }
   ],
   "source": [
    "println(\"skips: \", skipped_medium)\n",
    "\n",
    "println(\"mean implausibilities using DTC: \", mean_implausibilities_medium_dt)\n",
    "println(\"mean implausibilities using GCC: \", mean_implausibilities_medium_gc)\n",
    "\n",
    "println(\"Using Decision Threshold Convergence:\")\n",
    "\n",
    "println(\"valid switches: \", total_validity_medium_dt)\n",
    "println(\"mean: \", mean(mean_implausibilities_medium_dt))\n",
    "println(\"std: \", std(mean_implausibilities_medium_dt))\n",
    "\n",
    "println(\"Using Generator Conditions Convergence:\")\n",
    "\n",
    "println(\"valid switches: \", total_validity_medium_gc)\n",
    "println(\"mean: \", mean(mean_implausibilities_medium_gc))\n",
    "println(\"std: \", std(mean_implausibilities_medium_gc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 30 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 40 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 50 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 60 of split 1 reached\n",
      "datapoint 70 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 1 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 1 reached\n",
      "datapoint 100 of split 1 reached\n",
      "here!\n",
      "datapoint 10 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 2 reached\n",
      "datapoint 30 of split 2 reached\n",
      "datapoint 40 of split 2 reached\n",
      "datapoint 50 of split 2 reached\n",
      "datapoint 60 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 70 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 2 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 100 of split 2 reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  40%|█████████████████                        |  ETA: 0:06:58\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 3 reached\n",
      "datapoint 30 of split 3 reached\n",
      "datapoint 40 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 50 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 60 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 70 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 3 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 100 of split 3 reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  60%|█████████████████████████                |  ETA: 0:04:40\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 30 of split 4 reached\n",
      "datapoint 40 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 50 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 60 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 70 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 4 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 4 reached\n",
      "datapoint 100 of split 4 reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  80%|█████████████████████████████████        |  ETA: 0:02:22\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here!\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 10 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 20 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 30 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 40 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 50 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "Skipping because of model misclassification\n",
      "datapoint 70 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 80 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 90 of split 5 reached\n",
      "Skipping because of model misclassification\n",
      "datapoint 100 of split 5 reached"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:11:44\u001b[39m\u001b[K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5-element Vector{Any}:\n",
       " 1.2676878286376387\n",
       " 1.3645726726615375\n",
       " 1.3164353558399768\n",
       " 1.3017174688659383\n",
       " 1.4549688923239505"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_implausibilities_weak_dt = []\n",
    "mean_implausibilities_weak_gc = []\n",
    "total_validity_weak_dt = 0\n",
    "total_validity_weak_gc = 0\n",
    "model_to_use = adv_pgd_weak\n",
    "skipped_weak = 0\n",
    "\n",
    "@showprogress for (i, split) in enumerate(splits)\n",
    "    println(\"here!\")\n",
    "    implausibilities_dt = []\n",
    "    implausibilities_gc = []\n",
    "    for (j, index) in enumerate(split)\n",
    "\n",
    "        model_pred = (model_to_use(x_test[:, index]) |> Flux.onecold |> getindex) - 1\n",
    "        if model_pred != y_test[index]\n",
    "            skipped_weak += 1\n",
    "            println(\"Skipping because of model misclassification\")\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        if (j % 10 == 0)\n",
    "            println(\"datapoint $j of split $i reached\")\n",
    "        end\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for convergence in convergences\n",
    "            ce = generate_counterfactual(\n",
    "            reshape(x_test'[index, :], 8, 1), targets[i][j], counterfactual_data, flux_adv_weak, generator; num_counterfactuals=1, convergence=convergence\n",
    "            )\n",
    "\n",
    "            implausibility = distance_from_targets(ce)\n",
    "\n",
    "            if count == 0\n",
    "                total_validity_weak_gc += evaluate(ce; measure=validity)[1][1]\n",
    "                push!(implausibilities_gc, implausibility)\n",
    "            elseif count == 1\n",
    "                total_validity_weak_dt += evaluate(ce; measure=validity)[1][1]\n",
    "                push!(implausibilities_dt, implausibility)\n",
    "            end\n",
    "            \n",
    "            count += 1\n",
    "        end\n",
    "    end\n",
    "    push!(mean_implausibilities_weak_dt, mean(implausibilities_dt))\n",
    "    push!(mean_implausibilities_weak_gc, mean(implausibilities_gc))\n",
    "end\n",
    "\n",
    "mean_implausibilities_weak_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skips: 70\n",
      "mean implausibilities using DTC: Any[1.2676878286376387, 1.3645726726615375, 1.3164353558399768, 1.3017174688659383, 1.4549688923239505]\n",
      "mean implausibilities using GCC: Any[2.027445888388999, 2.105669214505507, 2.1845605486629203, 2.0210585454905257, 2.230242890262945]\n",
      "Using Decision Threshold Convergence:\n",
      "valid switches: 429.0\n",
      "mean: 1.3410764436658085\n",
      "std: 0.07257024796818826\n",
      "Using Generator Conditions Convergence:\n",
      "valid switches: 429.0\n",
      "mean: 2.113795417462179\n",
      "std: 0.09312642144456523\n"
     ]
    }
   ],
   "source": [
    "println(\"skips: \", skipped_weak)\n",
    "\n",
    "println(\"mean implausibilities using DTC: \", mean_implausibilities_weak_dt)\n",
    "println(\"mean implausibilities using GCC: \", mean_implausibilities_weak_gc)\n",
    "\n",
    "println(\"Using Decision Threshold Convergence:\")\n",
    "\n",
    "println(\"valid switches: \", total_validity_weak_dt)\n",
    "println(\"mean: \", mean(mean_implausibilities_weak_dt))\n",
    "println(\"std: \", std(mean_implausibilities_weak_dt))\n",
    "\n",
    "println(\"Using Generator Conditions Convergence:\")\n",
    "\n",
    "println(\"valid switches: \", total_validity_weak_gc)\n",
    "println(\"mean: \", mean(mean_implausibilities_weak_gc))\n",
    "println(\"std: \", std(mean_implausibilities_weak_gc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
